{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5210a7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34be83c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Management Libraries and Helper Functions\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "from breed_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f41bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object anda Data Structure Management Libraries\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37ff50e8",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root = 'data/Images'\n",
    "annot_root = 'data/Annotation'\n",
    "\n",
    "dog_paths = np.array(glob.glob(image_root + '/*/*'))\n",
    "annotations = np.array(glob.glob(annot_root + '/*/*'))\n",
    "breed_list = [x.split('-', 1)[-1] for x in os.listdir(image_root)]\n",
    "\n",
    "for i in range(len(annotations)):\n",
    "        dog_paths[i] = dog_paths[i].replace('\\\\','/')\n",
    "        annotations[i] = annotations[i].replace('\\\\','/')\n",
    "\n",
    "# for i in range(len(breed_list)):\n",
    "#     breed_list[i] = breed_list[i].split('-', 1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f50fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "        {'Breed': [get_dog_breed(x) for x in annotations], \n",
    "        'Folder_Dir': [x.split('/')[2].split('-')[0] for x in annotations], \n",
    "        'Image_Dir': [x.split('/')[-1] for x in annotations],\n",
    "        'Bbox': [get_bbox(x) for x in annotations],\n",
    "        'Num_Dogs': [len(get_bbox(x)) for x in annotations],\n",
    "        'Image_Path': dog_paths})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(breed_list)\n",
    "print(annotations)\n",
    "print(dog_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08b0fa24",
   "metadata": {},
   "source": [
    "### Viewing/Expiriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    if (np.shape(images[i]) != (299, 299, 3)):\n",
    "        print(i)\n",
    "        print(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = df['Image_Path'].iloc[13680]\n",
    "item = Image.open(item).convert('RGB').resize((desired_width, desired_height))\n",
    "np.shape(np.asarray(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5b6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_len = list()\n",
    "y_len = list()\n",
    "\n",
    "for bbox_arr in df.Bbox:\n",
    "    for bbox in bbox_arr:\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        x_len.append(xmax-xmin)\n",
    "        y_len.append(ymax-ymin)\n",
    "\n",
    "x_avg = sum(x_len)/len(x_len)\n",
    "x_min = min(x_len)\n",
    "x_max = max(x_len)\n",
    "\n",
    "y_avg = sum(y_len)/len(y_len)\n",
    "y_min = min(y_len)\n",
    "y_max = max(y_len)\n",
    "\n",
    "print(f'x_min: {x_min}, x_avg: {x_avg}, x_max: {x_max}, y_min: {y_min}, y_avg: {y_avg}, y_max: {y_max}')\n",
    "print(sorted(x_len, reverse=True))\n",
    "print(sorted(y_len, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotations[0])\n",
    "assert get_image_path(annotations[0]) == dog_paths[0]\n",
    "print(dog_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    print(get_bbox(annotations[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "\n",
    "    bbox = get_bbox(annotations[i])\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    dog = get_image_path(annotations[i])\n",
    "    im = Image.open(dog)\n",
    "    #im = im.resize((256,256), Image.ANTIALIAS)\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    for j in range(len(bbox)):\n",
    "        xmin, ymin, xmax, ymax = bbox[j]\n",
    "        plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin]) # showing border\n",
    "        plt.text(xmin, ymin, get_dog_breed(annotations[i]), bbox={'ec': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e330d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_cropped():\n",
    "#     #plt.figure(figsize=(10,6))\n",
    "#     for i in range(len(dog_image_paths)):\n",
    "#         bbox = get_bbox(annotations[i])\n",
    "#         dog = get_image_path(annotations[i])\n",
    "#         im = Image.open(dog)\n",
    "#         for j in range(len(bbox)):\n",
    "#             im2 = im.crop(bbox[j])\n",
    "#             #im2 = im2.resize((331,331), Image.ANTIALIAS)\n",
    "#             new_path = dog.replace('data/Images/','data/Cropped/')\n",
    "#             new_path = new_path.replace('.jpg', '-' + str(j) + '.jpg')\n",
    "#             im2 = im2.convert('RGB')\n",
    "#             head, tail = os.path.split(new_path)\n",
    "#             Path(head).mkdir(parents=True, exist_ok=True)\n",
    "#             im2.save(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f7c3a",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68ed0ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/shuffled_brute_resized_299_images.pickle', 'rb') as file:\n",
    "    X, y = pickle.load(file).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c50cd81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size:(20580, 299, 299, 3), y size:(20580,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X size:{np.shape(X)}, y size:{np.shape(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7145e362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train, test, val:  16464 2058 2058\n",
      "y train, test, val:  16464 2058 2058\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5, stratify = y_test, random_state = 1)\n",
    "print(\"X train, test, val: \", len(X_train), len(X_test), len(X_val))\n",
    "print(\"y train, test, val: \", len(y_train), len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c9a51",
   "metadata": {},
   "source": [
    "### Model Defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lr_scheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000, ramp_scalar=1, decay_scalar=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.ramp_scalar = ramp_scalar\n",
    "        self.decay_scalar = decay_scalar\n",
    "        \n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step) * self.decay_scalar\n",
    "        arg2 = step * (self.warmup_steps ** -1.5) * self.ramp_scalar\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"d_model\": self.d_model,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "        }\n",
    "    \n",
    "    def from_config(cls, config):\n",
    "         return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f71a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomTranslation(0.1, 0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomRotation(0.2),\n",
    "        layers.RandonContrast(0.1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddb815",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_learning = keras.Sequential(\n",
    "    layers.Conv2D(32, filter_size=5, activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=3, stride=2),\n",
    "\n",
    "    layers.Conv2D(64, filter_size=3, activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=2, stride=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = keras.Sequential(\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(120, activation='softmax'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1040aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    data_augmentation,\n",
    "    feature_learning,\n",
    "    classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c3ba8",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_layers = 4\n",
    "dff = 2048\n",
    "\n",
    "cnn_modules = 4\n",
    "d_model = 128\n",
    "\n",
    "dropout_rate = 0.2\n",
    "\n",
    "epochs = 50\n",
    "num_classes = df.Breed.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0dc13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87dfff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0dcd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4908aaa0",
   "metadata": {},
   "source": [
    "### Training Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237557ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e51d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "#plt.axis([75, 200, 1.2, 2.2])\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = lr_scheduler(d_model)\n",
    "lr = np.array([])\n",
    "for i in range(1, 100):\n",
    "    lr = np.append(lr, learning_rate.__call__(300*i))\n",
    "plt.title('Learning Rate')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.plot(lr, label='Learning Rate')\n",
    "#plt.axis([0, 300, 0, 0.000125])\n",
    "plt.legend()\n",
    "\n",
    "# learning_rate = lr_scheduler(d_model, ramp_scalar=1, decay_scalar=1)\n",
    "# steps_per_epoch = np.ceil((np.shape(X_train)[0]/batch_size))\n",
    "# print(steps_per_epoch)\n",
    "# lr = np.array([])\n",
    "# for i in range(1, np.maximum(epochs+10, 30)):\n",
    "#     lr = np.append(lr, learning_rate.__call__((i*steps_per_epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9b9282",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_cm(cm):\n",
    "    return np.array([cm[i] / np.sum(cm[i]) for i in range(len(cm))])\n",
    "def accuracy(cm):\n",
    "    return cm.diagonal().sum() / cm.sum()\n",
    "cm = confusion_matrix(y_test, np.argmax(pred, axis=1))\n",
    "\n",
    "normalized_cm = norm_cm(cm)\n",
    "print('accuracy', accuracy(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f613a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, xticklabels=range(2, 11), yticklabels=range(2, 11), annot=True, fmt='g', square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc99b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(normalized_cm, xticklabels=range(2, 11), yticklabels=range(2, 11), annot=True, fmt='.2f', square=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
